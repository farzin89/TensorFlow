# -*- coding: utf-8 -*-
"""03. Convolutional Neural Networks and Computer Vision with TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1If7ZGs8Hv6Y6-uLofCXAYtIGzKoK4BdS

## Introduction to Convolution Neural Networks and Computer Vision with TensorFlow

### computer vision is the practice of writing algorithms which can discover patterns in vissual . Such as the camera of a self - driving car recognizing the car in front.

## Get the data 

### The images we're working with are from the Food101 dataset (101 different classes of food): https://www.kaggle.com/dansbecker/food-101

However we've modified it to only use two classes (pizza & steak) using the image data modification notebook: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_data_modification.ipynb

## Note : We start with a smaller dataset so we can experiment quickly and figure what works (or better yet what doesn't work) before scaling up.
"""

import zipfile

!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip

# Unzip the downloaded file 

zip_ref = zipfile.ZipFile("pizza_steak.zip")
zip_ref.extractall()
zip_ref.close

"""## Inspect the data (become one with it)

#### A very crucial step at the beginning of any machine learning project is becoming one with the data.

And for a computer vision project... this usually means visualizing many samoles of your data.
"""

!ls pizza_steak

!ls pizza_steak/train/

!ls pizza_steak/train/steak

import os 

# Walk through pizza_steak directory and list number of files 

for dirpath,dirnames,filenames in os.walk("pizza_steak"):
  print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")

# The extra file in our pizza_steak directory is ".DS_store"
!ls -la pizza_steak

# Another way to find out how many images are in a file
num_steak_images_train = len(os.listdir("pizza_steak/train/steak"))
num_steak_images_train

"""### To visualize our images, first Let's get the class names programmatically."""

# Get the classsnames programmatically 

import pathlib 
import numpy as np
data_dir = pathlib.Path("pizza_steak/train")
class_names = np.array(sorted([item.name for item in data_dir.glob("*") ])) # Created a list of class_names from the subdirectories
print(class_names)

# Let's visualize our images 

import matplotlib.pyplot as plt
import matplotlib.image as mpimg 
import random 

def view_random_image(target_dir,target_class):
  # Setup the target directory (we'll view images from here)
  target_folder = target_dir+target_class
 
  # Get a random image path 
  random_image = random.sample(os.listdir(target_folder),1)
  print(random_image)
  # Read in the image and plot it using matplotlib
  img = mpimg.imread(target_folder + "/" + random_image[0])
  plt.imshow(img)
  plt.title(target_class)
  plt.axis("off");

  print(f"Image shape: {img.shape}") # show the shape of the image


return img

# View a random image from the training dataset

img = view_random_image(target_dir="pizza_steak/train/",
                        target_class="pizza")

# The images we've imported and plotted are actually gaint arrays/tensors of different pixel values

import tensorflow as tf

tf.constant(img)

# View the image shape
img.shape  # Returns width, height, colour channels

"""## Note : As we've discussed before, many machine learning models, including neural networks prefer the values they work with to be between 0 and 1. knowing this , one of the most common preprocessing steps for working with images is to scale (also referred to as normalize) their pixel values by dividing the image array by 255.(since 255 is the maximum pixel value)."""

# Get all the pixel values between 0 & 1

img / 255

"""## An end-to-end example

### Let's build a convolutional neural network to find patterns in our images, more specifically we a need way t:  

#### - Load our images 
#### - Preprocess our images 
#### - Build a CNN to find patterns in our images 
#### - Compile our CNN 
#### - Fit the CNN to our training data 



"""

from tensorflow.python.keras.backend import binary_crossentropy
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# set the seed

tf.random.set_seed(42)

# Preprocess data (get all of pixel values between 0 & 1 , also called scaling/normalization)

train_datagen = ImageDataGenerator(rescale=1. / 255)
valid_datagen = ImageDataGenerator(rescale=1. / 255)

# Setup paths to our data directories
train_dir = "/content/pizza_steak/train"
test_dir = "pizza_steak/test"

# Import data from directories and turn it into batches

train_data = train_datagen.flow_from_directory(directory=train_dir,
                                               batch_size=32,
                                               target_size=(224, 224),
                                               class_mode="binary",
                                               seed=42)
valid_data = train_datagen.flow_from_directory(directory=test_dir,
                                               batch_size=32,
                                               target_size=(224, 224),
                                               class_mode="binary",
                                               seed=42)

# Build a CNN model (same as the tiny VGG on the CNN explainer Website)

model_1 = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(filters=10,
                         kernel_size=3,
                         activation="relu",
                         input_shape=(224, 224, 3)),

  tf.keras.layers.Conv2D(10, 3, activation="relu"),
  tf.keras.layers.MaxPool2D(pool_size=2,
                            padding="valid"),
  tf.keras.layers.Conv2D(10, 3, activation="relu"),
  tf.keras.layers.MaxPool2D(2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(1, activation="sigmoid")

])

# Compile our CNN
model_1.compile(loss="binary_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"]
                )
# fit the model

history_1 = model_1.fit(train_data,
                        epochs=5,
                        steps_per_epoch=len(train_data),
                        validation_data=valid_data,
                        validation_steps=len(valid_data))

"""### Note : If the above cell is talking longer than 10 seconds per epoch, make sure you're using a GPU by going to Runtime-> Change Runtime Type-> Hardware Acccelator -> GPU(you may have to rerun some cell above)"""

# Get a model summary

model_1.summary()

"""
### Practice/exercise: Go through the CNN explainer website for a minimum of 10-minute and compare our neural network with thiers : https://poloclub.github.io/cnn-explainer/"""

