# -*- coding: utf-8 -*-
"""05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18xH5I3cuJzatkEsf43LhBr8rNDcB1en2

# Teansfer learning with TensorFlow part 2 : Fine-tuning 

In the previous notebook, we covered transfer learning feature extraction, now it's time to learn about a new kind of transfer learning: fine-tuning.
"""

# check if we're using a GPU

!nvidia-smi

"""## Creating helper function 

in previous notebook we've created a bunch of helper function, now we could rewrite them all, however, this is tedious.

So, it's a good idea to put functions you'll want to use again in a script you can download and import into your notebooks (or elsewhere)

we've done this for same of the functions we've used previously here:
https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py
"""

!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py

# Import helper functions we're going to use in this notebook 

from helper_functions import create_tensorboard_callback,plot_loss_curves,unzip_data, walk_through_dir

"""**Note:** If you're running this notebook in Google colab, when it times out colab will delete helper_function.py , so you have to redownload it if you want access to your helper functions.

## Let's get some data 

This time we're going to see how we can use the pretrained models within **tf.keras.applications** and apply them to our own problem (recognizing imsges of food). 
link : https://www.tensorflow.org/api_docs/python/tf/keras/applications
"""

# Get 10% of training data of 10 classes of Food101
 !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip

 unzip_data("10_food_classes_10_percent.zip")

# check out how many images and subdirectories are in our dataset
walk_through_dir("10_food_classes_10_percent")

# create training and test directory paths
train_dir = "10_food_classes_10_percent/train"
test_dir = "10_food_classes_10_percent/test"

import tensorflow as tf
IMG_SIZE = (224,224)
BATCH_SIZE = 32
train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory = train_dir,
                                                                            image_size = IMG_SIZE,
                                                                            label_mode ="categorical",
                                                                            batch_size = BATCH_SIZE)
test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,
                                                                image_size = IMG_SIZE,
                                                                label_mode="categorical",
                                                                batch_size = BATCH_SIZE)

train_data_10_percent

# check out the class names of our dataset 
 train_data_10_percent.class_names

# See an example of a batch of data

for images,labels in train_data_10_percent.take(1):
  print(images,labels)
  
"""## Model 0 : Building a transfer learning feature extraction model using the keras functional API

The sequential API is straight-forward, it runs our layers in sequential order.

But the functional API gives us more flexibility with our model. https://www.tensorflow.org/guide/keras/functional

"""

# 1. Create base model with tf.keras.applications
base_model = tf.keras.applications.EfficientNetB0(include_top = False)

# 2. Freeze the base model(so the underlying pre-trains aren't updated during training )
base_model.trainable = False

# 3. Create inpute into our model
inputs = tf.keras.layers.Input(shape= (224,224,3),name="input_layer")

# 4. If using a model like ResNet50V2 you will need to normlize inputs(you don't have to for EfficientNet(s))
# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)

# 5. pass the inputs to the base_model
 x = base_model(inputs)
 print(f"Shape after passing inputs through base model: {x.shape}")

 # 6. Average pool the outputs of the base model (aggregate all the most important information,reduce number of computations)
 x = tf.keras.layers.GlobalAveragePooling2D(name = "global_average_pooling_layer")(x)
 print(f"shape after GlobalAveragePooling2D: {x.shape}")

 # 7. Create the output activation layer
 outputs = tf.keras.layers.Dense(10,activation="softmax",name = "output_layer")(x)

 # 8 . combine the inputs with the outputs into a model
 model_0 = tf.keras.Model(inputs,outputs)

# 9. Compile the model
model_0.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(),
              metrics=["accuracy"])

# 10. Fit the model (we use less steps for validation so it's faster)
history_10_percent = model_0.fit(train_data_10_percent,
                                 epochs=5,
                                 steps_per_epoch=len(train_data_10_percent),
                                 validation_data=test_data,
                                 # Go through less of the validation data so epochs are faster (we want faster experiments!)
                                 validation_steps=int(0.25 * len(test_data)),
                                 # Track our model's training logs for visualization later
                                 callbacks=[create_tensorboard_callback("transfer_learning", "10_percent_feature_extraction")])

# Evaluate on the full test dataset
model_0.evaluate(test_data)

# Check the layers in our base model
for layer_number,layer in enumerate(base_model.layers):
  print(layer_number,layer.name)

# how about we get a summary of the model
base_model.summary()

# how about a summary of our whole model ?
model_0.summary()

# Check out our model's training curves
plot_loss_curves(history_10_percent)

"""## Getting a feature vector from a train model 

Let's demonstrate the Global Average pooling 2D layer...

We have a tensor after our model goes through 'base_model' of shape(None,7,7,1280).

But then when it passes through GlobalAveragePooling2D, it turns into (None, 1280)

Let's use a similar shaped tensor of (1,4,4,3) and then pass it to GlobalAveragePooling2D .

"""

# Define the inpot shape

input_shape = (1,4,4,3)

# Create a random tensor
tf.random.set_seed(42)
input_tensor = tf.random.normal(input_shape)
print(f"Random input tensor:\ {input_tensor}\n")

# Pass the random tensor through a global average pooling 2D layer
global_average_pooled_tensor = tf.keras.layers.GlobalAvgPool2D()(input_tensor)
print(f"2D global average pooled random tensor:\n {global_average_pooled_tensor}\n")

# Check the shape of the different tensors
print(f"shape of input tensore:{input_tensor.shape}")
print(f"shape of Glabal Average Pooled 2D tensor:{global_average_pooled_tensor.shape}")

# Let's replicate the GlobalAveragePool2D layer
tf.reduce_mean(input_tensor,axis=[1,2])

"""**practice:** Try to do the same with the above two cells but this time use 'GlobalMaxpool2D' and see what happens."""
**Note:** one of the reason feature extraction transfer learning is named how it is because what often happens is pretrained model outputs a **feature vector** (a long tensor of numbers which represents the learned representation of the model on a particular sample, in our case, this is the output of ' tf.keras.layers.GlobalAveragepooling2D()' layer) which can then be used to extract patterns out of our own specific problem.

## Running a series of transfer learning experiments

we've seen the incredible results transfer learning can get with only 10 % of the training data , but how does it go with 1% of the training data... how about we set up a bunch of experiments to find out :

1. 'model_1' - use feature extraction transfer learning with 1 % of trainig data with data augmentation
2. 'model_2'-  use feature extraction transfer learning with 10% of the training with data augmentation
3. 'model_3'- use fine-tuning transfer learning on 10 % of the training data with data augmentation
4. 'model_4'- use fine-tuning transfer learning on 100 % of the training data with data augmentation

**Note** : throughout all experiments the same test dataset will be used to evaluate our model... this ensures consistency across evaluation metrics.

### Getting and preprocessing data for model_1


# Download and unzip data - preprocessed from food101
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip
unzip_data("10_food_classes_1_percent.zip")

train_dir_1_percent = "10_food_classes_1_percent/train"
test_dir= "10_food_classes_1_percent/test"

# How many images are we working with? 
walk_through_dir("10_food_classes_1_percent")

# Setup data loaders 
IMG_SIZE = (224,224)
train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_1_percent,
                                                                           label_mode = "categorical",
                                                                           image_size = IMG_SIZE,
                                                                           batch_size=BATCH_SIZE) # default = 32
test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,
                                                                label_mode = "categorical",
                                                                image_size = IMG_SIZE,
                                                                batch_size = BATCH_SIZE)

"""## Adding data augmentation right into the model

To add data augmentation right into our models,we can use the layers inside:
* 'tf.keras.layers.experimental.preprocessins() '

we can see the benefits of doing this within the TensorFlow Data augmentation documentation : https://www.tensorflow.org/tutorials/images/data_augmentation#use_keras_preprocessing_layers

off the top our of heads, after reading the the docs,the benefits of using data augmentation inside the model are :
* Preprocessing of image ( augmenting them) happens on the GPU (much faster) rather than the CPU.
* Image data augmentation only happens during training, so we can still export our whole model and use it elsewhere."""



import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import  layers
from tensorflow.keras.layers.experimental import preprocessing

# Create data augmentation stage with horizontal flipping , rotations,zooms,etc
data_augmentation =  keras.Sequential([
    preprocessing.RandomFlip("horizontal"),
    preprocessing.RandomRotation(0.2),
    preprocessing.RandomZoom (0.2),
    preprocessing.RandomHeight(0.2),
    preprocessing.RandomWidth(0.2),
    #preprocessing.Rescale(1./255) # Keep for models like ResNet50v2 but EfficientNet's having rescaling built-in
],name = "data_augmentation")

## Visualize our data augmentation layer(and see what happens to our data)

# View a random image and compare it to its augmented version
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os
import random
target_class = random.choice(train_data_1_percent.class_names)
target_dir = "10_food_classes_1_percent/train/" + target_class
random_image = random.choice(os.listdir(target_dir))
random_image_path = target_dir + "/" + random_image

# Read in the random image
img = mpimg.imread(random_image_path)
plt.imshow(img)
plt.title(f"Original random image from class: {target_class}")
plt.axis(False)

# Now let's plot our augmented random image
augmented_img = data_augmentation(tf.expand_dims(img,axis=0))
plt.figure()
plt.imshow(tf.squeeze(augmented_img)/255.)
plt.title(f"Augmented random image from class:{target_class}")
plt.axis(False)

"""## Model 1: Feature extraction transfer learning on 1% of the data with data augmentation """

#setup input shape and base model, freezing the base model layers
input_shape = (224,224,3)
base_model = tf.keras.applications.EfficientNetB0(include_top=False)
base_model.trainable = False

# Create input layer
inputs = layers.Input(shape=input_shape,name="input_layer")

# Add in data augmentation Sequential model as a layer
x = data_augmentation(inputs)

# Give base_model the inputs (after augmentation) and don't train it
x = base_model(x,training = False)

# Pool output features of the base model
x = layers.GlobalAvgPool2D(name = "global")(x)

# put a dense layer on as the output
outputs = layers.Dense(10,activation="softmax",name = "output_layer")(x)

# Make a model using the inputs and outputs
model_1 = keras.Model(inputs,outputs)

# Compile the model
model_1.compile(loss = "categorical_crossentropy",
                optimizer = tf.keras.optimizers.Adam(),
                metrics = ["accuracy"])

# Fit the model

history_1_percent = model_1.fit(train_data_1_percent,
                                epochs = 5,
                                steps_per_epoch = len(train_data_1_percent),
                                validation_data = test_data,
                                validation_steps =int(0.25 * len(test_data)),
                                #Track model training logs
                                callbacks = [create_tensorboard_callback(dir_name= "transfer_learning",
                                                                        experiment_name = "1_percent_data_aug")])
# check out a model summary
model_1.summary()

# Evaluate on the full test dataset
results_1_percent_data_aug = model_1.evaluate(test_data)
results_1_percent_data_aug

# How do the model with 1 % of data augmentation loss curves look?
plot_loss_curves(history_1_percent)

"""## model 2 : feature extraction transfer learning model with 10% of data and data augmentation 



"""

# Get 10% of data ...(uncomment if you don't have it )
# !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip
# unzip_data(10_food_classes_10_percent)

train_dir_10_percent = "10_food_classes_10_percent/train"
test_dir = "10_food_classes_10_percent/test"

# How many images are in our directories?
walk_through_dir("10_food_classes_10_percent")

# Set data inputs
import tensorflow as tf

IMG_SIZE = (224, 224)
train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_10_percent,
                                                                            label_mode="categorical",
                                                                            image_size=IMG_SIZE)
test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,
                                                                label_mode="categorical",
                                                                image_size=IMG_SIZE)

# create model 2 with data augmentation built in
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras.models import Sequential

# Build data augmentation
data_augmentation = Sequential([
    preprocessing.RandomFlip('horizontal'),
    preprocessing.RandomHeight(0.2),
    preprocessing.RandomWidth(0.2),
    preprocessing.RandomZoom(0.2),
    preprocessing.RandomRotation(0.2),
    # preprocessing.Rescaling(1./255) # if you're using a model such as ResNet50v2, you'll need to rescale your data,efficientnet has rescaling built-in

], name="data_augmentation")

# Setup the input shape to our model
input_shape = (224, 224, 3)

# Create a frozen base model (also called the backbone)
base_model = tf.keras.applications.EfficientNetB0(include_top=False)
base_model.trainable = False

# Create the inputs and outputs (including the layers in between)
inputs = layers.Input(shape=input_shape, name="input_layer")
x = data_augmentation(inputs)  # augment our training images(augmentation doesn't occure on test data)
x = base_model(x,
               training=False)  # pass the augmented images to base model but keep it in inference mode,this also insures batchnorm layers don't get updated - https://keras.io/guides/transfer_learning/#build-a-model
x = layers.GlobalAveragePooling2D(name="global_average_pooling_2D")(x)
outputs = layers.Dense(10, activation="softmax", name="output_layer")(x)
model_2 = tf.keras.Model(inputs, outputs)

# Compile the model

model_2.compile(loss="categorical_crossentropy",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["accuracy"])

"""### Creating a ModelCheckpoint callback 

The ModelCheckpoint callback intermediately saves our model(the full model or just the weights) during training. This is useful so we can come and start where we left off.
"""

# Set checkpoint path
checkpoint_path = "ten_percent_model_checkpoints_weights/checkpoint.ckpt"

# Create a Modelcheckpoint callback that saves the model's weights only
checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                         save_weights_only=True,
                                                         save_best_only=False,
                                                         save_freq="epoch",  # save every epoch,
                                                         verbose=1)

"""### Fit model 2 passing in the ModelCheckpoint callbacks

"""

# Fit the model saving checkpoints every epoch
initial_epochs = 5
history_10_percent_data_aug = model_2.fit(train_data_10_percent,
                                          epochs=initial_epochs,
                                          validation_data=test_data,
                                          validation_steps=int(0.25 * len(test_data)),
                                          callbacks=[create_tensorboard_callback(dir_name="transfer_learning",
                                                                                 experiment_name="10_percent_data_aug"),
                                                     checkpoint_callback])

# what were model_0 results?
model_0.evaluate(test_data)

# Check model_2 results on all test_data
results_10_percent_data_aug = model_2.evaluate(test_data)
results_10_percent_data_aug

# plot model loss curves
plot_loss_curves(history_10_percent_data_aug)

"""### Loading in checkpointed weights 

loading in checkpointed weights returns a model to a specific checkpoint
"""

# Load in saved model weights and evaluate nodel
model_2.load_weights(checkpoint_path)

# Evaluate model_2 with loaded weights
loaded_weights_model_results = model_2.evaluate(test_data)

# If the results from our previously evaluated model_2 match the loaded weights, everything has worked!
results_10_percent_data_aug == loaded_weights_model_results

results_10_percent_data_aug

loaded_weights_model_results

# check to see if loaded model results are very close to our previous non-loaded model results
import numpy as np
np.isclose(np.array(results_10_percent_data_aug),np.array(loaded_weights_model_results))

# check the difference between the two results
print(np.array(results_10_percent_data_aug)- np.array(loaded_weights_model_results))

"""## Model_3: Fine-tuning an existing model on 10% of the data

**Note:** Fine-tuning usually works best after training a feature extraction model for a few epochs with large amounts of custom data.

"""

# Layers in loaded model
model_2.layers

# Are these layers trainable ?
for layer in model_2.layers:
  print(layer,layer.trainable)

# What layers are in our base_model (EfficientNetB0) and are they trainable?
for i,layer in enumerate(model_2.layers[2].layers):
  print(i,layer.name,layer.trainable)

# How many trainable variable are in our base model ?
print(len(model_2.layers[2].trainable_variables))

# To begin fine-tuning, let's start by setting the last 10 layers of our base_model.trainable = True
base_model.trainable = True
# Freeze all layers exceot for the last 10
for layer in base_model.layers[:-10]:
  layer.trainable = False

# Recompile (we have to recompile our models every time we make a change)
model_2.compile(loss="categorical_crossentropy",
                optimizer = tf.keras.optimizers.Adam(lr=0.0001),# when fine-tuning you typically want to lower the learning rate by 10x*
                metrics =["accuracy"])

"""**Note:** when using fine-tuning it's best practie to lower your learning rate by some amount. How much ? This is hyperparameter you can tune. But a good rule of thumb is at least 10x (though different sources wii claim other values) . A good resource for information on this is the ULMFIT paper : https://arxiv.org/abs/1801.06146"""

# check which layers are tunable (trainable)
for layer_number,layer in enumerate(model_2.layers[2].layers):
 print(layer_number,layer.name, layer.trainable)

# Now we've unfrozen some of the layers closer to the top, how many trainable variable are there?
print(len(model_2.trainable_variables))

# Fine tune for another 5 epochs
fine_tune_epochs = initial_epochs + 5

# Refit the model (same as model_2 except with more trainable layers)
history_fine_10_percent_data_aug = model_2.fit(train_data_10_percent,
                                               epochs = fine_tune_epochs,
                                               validation_data = test_data,
                                               validation_steps = int(0.25 * len(test_data)),
                                               initial_epoch = history_10_percent_data_aug.epoch[-1], #start training from previous last epoch
                                               callbacks = [create_tensorboard_callback(dir_name="transfer_learning",
                                                                                        experiment_name = "10_percent_fine_tune_last_10")])

# Evaluate the fine-tuned model (model_3 which is actualy model_2 fine-tuned for another 5 epochs )
results_fine_tune_10_percent = model_2.evaluate(test_data)

# Check out the loss curves of our fine-tuned model
plot_loss_curves(history_fine_10_percent_data_aug)

"""The 'plot_loss_curves' function works great with models which have only been fit once,however, we want something to compare one series of running 'fit()' with another (e.g before and after fine-tuning)."""

# Let's create a function to compare training histories
def compare_historys(original_history , new_history,initial_epochs = 5):
  """
  Compares two TensorFlow History objects.
  """
  # Get original history measurments
  acc = original_history.history["accuracy"]
  loss = original_history.history["loss"]

  val_acc = original_history.history["val_accuracy"]
  val_loss = original_history.history["val_loss"]

  # combine original history metrics with new_history metrics
  total_acc = acc + new_history.history["accuracy"]
  total_loss = loss + new_history.history["loss"]

  total_val_acc = val_acc + new_history.history["val_accuracy"]
  total_val_loss = val_loss + new_history.history["val_loss"]

  # Make plots for accuracy
  plt.figure(figsize = (8,8))
  plt.subplot(2,1,1)
  plt.plot(total_acc, label ="Training accuracy")
  plt.plot (total_val_acc , label = "val accuracy ")
  plt.plot([initial_epochs-1,initial_epochs-1],plt.ylim(),label = "start Fine Tuning")
  plt.legend(loc = "lower right")
  plt.title("Training and Validation Acuuracy")

  # Make plots for loss
  plt.figure(figsize = (8,8))
  plt.subplot(2,1,2)
  plt.plot(total_loss, label ="Training loss")
  plt.plot (total_val_loss , label = " val loss ")
  plt.plot([initial_epochs-1,initial_epochs-1],plt.ylim(),label = "start Fine Tuning")
  plt.legend(loc = "upper right")
  plt.title("Training and Validation loss")

compare_historys(history_10_percent_data_aug,
                 history_fine_10_percent_data_aug,
                 initial_epochs =5)

"""## Model 4 : Fine-tuning and existing model on all of data"""

# Download and unzip 10 classes of Food101 data with all images
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip
unzip_data("10_food_classes_all_data.zip")

# Setup training and test dir
train_dir_all_data = "10_food_classes_all_data/train"
test_dir = "10_food_classes_all_data/test"

# How many images are we working with now?
walk_through_dir("10_food_classes_all_data")

# setup data inputs
import tensorflow as tf
IMG_SIZE = (224,224)
train_data_10_classes_full = tf.keras.preprocessing.image_dataset_from_directory(train_dir_all_data,
                                                                                 label_mode = "categorical",
                                                                                 image_size = IMG_SIZE)
test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,
                                                                label_mode = "categorical",
                                                                image_size = IMG_SIZE)

"""The test dataset we've loaded in is the same as what we've been using for previous experiments( all experiments have used the same test dataset).

Let's verfy this...
"""

# Evaluate model 2 (this is fine-tuned on 10 percent of data version)
model_2.evaluate(test_data)

results_fine_tune_10_percent

"""To train a fine-tuning model (model_4) we need to revert model_2 back to its feature extraction weights."""

# Load weight from checkpoint, that way we can fine-tune from
# the same stage the 10 percent data model was fine-tuned from
model_2.load_weights(checkpoint_path)

# Let's evaluate model_2 now
model_2.evaluate(test_data)

# Check to see if our model_2 has been reserved back to feature extraction results
results_10_percent_data_aug

"""Alright,the previous steps might seem quite confusing but all we've done is :    
1. Trrained afeature extraction transfer learning model for 5 epochs on 10% of the data with data augmentation (model_2) and we saved the model's weights using 'modelCheckpoint' callback.
2. Fine-tuned the same model on the same 10% of the data for a further 5 epochs with the top 10 layers of the base model unfrozen (model_3)
3. saved the results and training logs each time.
4. Reloaded the model we're going to use all of the data (model_4)




"""

# Check which layers are tunable in the whole model
for layer_number, layer in enumerate(model_2.layers):
  print(layer_number,layer.name,layer.trainable)

# Let's drill into our base_model (efficientnetb0) and see what layers are trainable
for layer_number,layer in enumerate (model_2.layers[2].layers):
  print(layer_number,layer.name,layer.trainable)

# Compile
 model_2.compile(loss = "categorical_crossentropy",
                 optimizer = tf.keras.optimizers.Adam(lr=0.0001),
                 metrics = ["accuracy"])

# continue to train and fine-tune the model to our data (100% of training data)
fine_tune_epochs = initial_epochs + 5

history_fine_10_classes_full = model_2.fit(train_data_10_classes_full,
                                           epochs = fine_tune_epochs,
                                            validation_data = test_data,
                                           validation_steps = int (0.25 * len (test_data)),
                                           initial_epoch = history_10_percent_data_aug.epoch[-1],
                                           callbacks = [create_tensorboard_callback(dir_name="transfer_learning",
                                                                                    experiment_name = "full_10_classes_fine_tune_last_10")])

# Let's evaluate on all of the test data
results_fine_tune_full_data = model_2.evaluate(test_data)
results_fine_tune_full_data

#How did fine-tuning go with more data?
compare_historys(original_history= history_10_percent_data_aug,
                 new_history = history_fine_10_classes_full,
                 initial_epochs = 5)

"""## Viewing our experiment data on TensorBoard 

**Note:** anything you upload to TensorBoard.dev is going to be public. so if you have private data, do not upload.
"""

# View tensorboard logs of transfer learning modelling experiments(should ~ 4 models)
# Upload TensorBoard dev records
!tensorboard dev upload --logdir ./transfer_learning\
  --name "Transfer learning Experiments with 10 Food101 classes"\
  --description " A series of different transfer learning experiments with varying amounts of data and fine-tuning."\
  --one_shot # exits the uploader once its finished uploading

"""My tensorBoard experiments are available at : https://tensorboard.dev/experiment/Xqbcke5mRE2dUGXI4LDAKw/"""

# View all of your uploaded TensorBoard.dev experiments (public)
!tensorboard dev list

# To delete an expreiment
#!tensorboard dev delet--experiment_id