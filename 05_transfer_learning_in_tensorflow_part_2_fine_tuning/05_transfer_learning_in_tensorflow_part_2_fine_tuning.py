# -*- coding: utf-8 -*-
"""05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18xH5I3cuJzatkEsf43LhBr8rNDcB1en2

# Teansfer learning with TensorFlow part 2 : Fine-tuning 

In the previous notebook, we covered transfer learning feature extraction, now it's time to learn about a new kind of transfer learning: fine-tuning.
"""

# check if we're using a GPU

!nvidia-smi

"""## Creating helper function 

in previous notebook we've created a bunch of helper function, now we could rewrite them all, however, this is tedious.

So, it's a good idea to put functions you'll want to use again in a script you can download and import into your notebooks (or elsewhere)

we've done this for same of the functions we've used previously here:
https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py
"""

!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py

# Import helper functions we're going to use in this notebook 

from helper_functions import create_tensorboard_callback,plot_loss_curves,unzip_data, walk_through_dir

"""**Note:** If you're running this notebook in Google colab, when it times out colab will delete helper_function.py , so you have to redownload it if you want access to your helper functions.

## Let's get some data 

This time we're going to see how we can use the pretrained models within **tf.keras.applications** and apply them to our own problem (recognizing imsges of food). 
link : https://www.tensorflow.org/api_docs/python/tf/keras/applications
"""

# Get 10% of training data of 10 classes of Food101
 !wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip

 unzip_data("10_food_classes_10_percent.zip")

# check out how many images and subdirectories are in our dataset
walk_through_dir("10_food_classes_10_percent")

# create training and test directory paths
train_dir = "10_food_classes_10_percent/train"
test_dir = "10_food_classes_10_percent/test"

import tensorflow as tf
IMG_SIZE = (224,224)
BATCH_SIZE = 32
train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory = train_dir,
                                                                            image_size = IMG_SIZE,
                                                                            label_mode ="categorical",
                                                                            batch_size = BATCH_SIZE)
test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,
                                                                image_size = IMG_SIZE,
                                                                label_mode="categorical",
                                                                batch_size = BATCH_SIZE)

train_data_10_percent

# check out the class names of our dataset 
 train_data_10_percent.class_names

# See an example of a batch of data

for images,labels in train_data_10_percent.take(1):
  print(images,labels)
  
"""## Model 0 : Building a transfer learning feature extraction model using the keras functional API

The sequential API is straight-forward, it runs our layers in sequential order.

But the functional API gives us more flexibility with our model. https://www.tensorflow.org/guide/keras/functional

"""

# 1. Create base model with tf.keras.applications
base_model = tf.keras.applications.EfficientNetB0(include_top = False)

# 2. Freeze the base model(so the underlying pre-trains aren't updated during training )
base_model.trainable = False

# 3. Create inpute into our model
inputs = tf.keras.layers.Input(shape= (224,224,3),name="input_layer")

# 4. If using a model like ResNet50V2 you will need to normlize inputs(you don't have to for EfficientNet(s))
# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)

# 5. pass the inputs to the base_model
 x = base_model(inputs)
 print(f"Shape after passing inputs through base model: {x.shape}")

 # 6. Average pool the outputs of the base model (aggregate all the most important information,reduce number of computations)
 x = tf.keras.layers.GlobalAveragePooling2D(name = "global_average_pooling_layer")(x)
 print(f"shape after GlobalAveragePooling2D: {x.shape}")

 # 7. Create the output activation layer
 outputs = tf.keras.layers.Dense(10,activation="softmax",name = "output_layer")(x)

 # 8 . combine the inputs with the outputs into a model
 model_0 = tf.keras.Model(inputs,outputs)

# 9. Compile the model
model_0.compile(loss='categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(),
              metrics=["accuracy"])

# 10. Fit the model (we use less steps for validation so it's faster)
history_10_percent = model_0.fit(train_data_10_percent,
                                 epochs=5,
                                 steps_per_epoch=len(train_data_10_percent),
                                 validation_data=test_data,
                                 # Go through less of the validation data so epochs are faster (we want faster experiments!)
                                 validation_steps=int(0.25 * len(test_data)),
                                 # Track our model's training logs for visualization later
                                 callbacks=[create_tensorboard_callback("transfer_learning", "10_percent_feature_extraction")])

# Evaluate on the full test dataset
model_0.evaluate(test_data)

# Check the layers in our base model
for layer_number,layer in enumerate(base_model.layers):
  print(layer_number,layer.name)

# how about we get a summary of the model
base_model.summary()

# how about a summary of our whole model ?
model_0.summary()

# Check out our model's training curves
plot_loss_curves(history_10_percent)

"""## Getting a feature vector from a train model 

Let's demonstrate the Global Average pooling 2D layer...

We have a tensor after our model goes through 'base_model' of shape(None,7,7,1280).

But then when it passes through GlobalAveragePooling2D, it turns into (None, 1280)

Let's use a similar shaped tensor of (1,4,4,3) and then pass it to GlobalAveragePooling2D .

"""

# Define the inpot shape

input_shape = (1,4,4,3)

# Create a random tensor
tf.random.set_seed(42)
input_tensor = tf.random.normal(input_shape)
print(f"Random input tensor:\ {input_tensor}\n")

# Pass the random tensor through a global average pooling 2D layer
global_average_pooled_tensor = tf.keras.layers.GlobalAvgPool2D()(input_tensor)
print(f"2D global average pooled random tensor:\n {global_average_pooled_tensor}\n")

# Check the shape of the different tensors
print(f"shape of input tensore:{input_tensor.shape}")
print(f"shape of Glabal Average Pooled 2D tensor:{global_average_pooled_tensor.shape}")

# Let's replicate the GlobalAveragePool2D layer
tf.reduce_mean(input_tensor,axis=[1,2])

"""**practice:** Try to do the same with the above two cells but this time use 'GlobalMaxpool2D' and see what happens."""
**Note:** one of the reason feature extraction transfer learning is named how it is because what often happens is pretrained model outputs a **feature vector** (a long tensor of numbers which represents the learned representation of the model on a particular sample, in our case, this is the output of ' tf.keras.layers.GlobalAveragepooling2D()' layer) which can then be used to extract patterns out of our own specific problem.

## Running a series of transfer learning experiments

we've seen the incredible results transfer learning can get with only 10 % of the training data , but how does it go with 1% of the training data... how about we set up a bunch of experiments to find out :

1. 'model_1' - use feature extraction transfer learning with 1 % of trainig data with data augmentation
2. 'model_2'-  use feature extraction transfer learning with 10% of the training with data augmentation
3. 'model_3'- use fine-tuning transfer learning on 10 % of the training data with data augmentation
4. 'model_4'- use fine-tuning transfer learning on 100 % of the training data with data augmentation

**Note** : throughout all experiments the same test dataset will be used to evaluate our model... this ensures consistency across evaluation metrics.

### Getting and preprocessing data for model_1


# Download and unzip data - preprocessed from food101
!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip
unzip_data("10_food_classes_1_percent.zip")

train_dir_1_percent = "10_food_classes_1_percent/train"
test_dir= "10_food_classes_1_percent/test"

# How many images are we working with? 
walk_through_dir("10_food_classes_1_percent")

# Setup data loaders 
IMG_SIZE = (224,224)
train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_1_percent,
                                                                           label_mode = "categorical",
                                                                           image_size = IMG_SIZE,
                                                                           batch_size=BATCH_SIZE) # default = 32
test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,
                                                                label_mode = "categorical",
                                                                image_size = IMG_SIZE,
                                                                batch_size = BATCH_SIZE)

"""## Adding data augmentation right into the model

To add data augmentation right into our models,we can use the layers inside:
* 'tf.keras.layers.experimental.preprocessins() '

we can see the benefits of doing this within the TensorFlow Data augmentation documentation : https://www.tensorflow.org/tutorials/images/data_augmentation#use_keras_preprocessing_layers

off the top our of heads, after reading the the docs,the benefits of using data augmentation inside the model are :
* Preprocessing of image ( augmenting them) happens on the GPU (much faster) rather than the CPU.
* Image data augmentation only happens during training, so we can still export our whole model and use it elsewhere."""



import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import  layers
from tensorflow.keras.layers.experimental import preprocessing

# Create data augmentation stage with horizontal flipping , rotations,zooms,etc
data_augmentation =  keras.Sequential([
    preprocessing.RandomFlip("horizontal"),
    preprocessing.RandomRotation(0.2),
    preprocessing.RandomZoom (0.2),
    preprocessing.RandomHeight(0.2),
    preprocessing.RandomWidth(0.2),
    #preprocessing.Rescale(1./255) # Keep for models like ResNet50v2 but EfficientNet's having rescaling built-in
],name = "data_augmentation")

## Visualize our data augmentation layer(and see what happens to our data)

# View a random image and compare it to its augmented version
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os
import random
target_class = random.choice(train_data_1_percent.class_names)
target_dir = "10_food_classes_1_percent/train/" + target_class
random_image = random.choice(os.listdir(target_dir))
random_image_path = target_dir + "/" + random_image

# Read in the random image
img = mpimg.imread(random_image_path)
plt.imshow(img)
plt.title(f"Original random image from class: {target_class}")
plt.axis(False)

# Now let's plot our augmented random image
augmented_img = data_augmentation(tf.expand_dims(img,axis=0))
plt.figure()
plt.imshow(tf.squeeze(augmented_img)/255.)
plt.title(f"Augmented random image from class:{target_class}")
plt.axis(False)

"""## Model 1: Feature extraction transfer learning on 1% of the data with data augmentation """

#setup input shape and base model, freezing the base model layers
input_shape = (224,224,3)
base_model = tf.keras.applications.EfficientNetB0(include_top=False)
base_model.trainable = False

# Create input layer
inputs = layers.Input(shape=input_shape,name="input_layer")

# Add in data augmentation Sequential model as a layer
x = data_augmentation(inputs)

# Give base_model the inputs (after augmentation) and don't train it
x = base_model(x,training = False)

# Pool output features of the base model
x = layers.GlobalAvgPool2D(name = "global")(x)

# put a dense layer on as the output
outputs = layers.Dense(10,activation="softmax",name = "output_layer")(x)

# Make a model using the inputs and outputs
model_1 = keras.Model(inputs,outputs)

# Compile the model
model_1.compile(loss = "categorical_crossentropy",
                optimizer = tf.keras.optimizers.Adam(),
                metrics = ["accuracy"])

# Fit the model

history_1_percent = model_1.fit(train_data_1_percent,
                                epochs = 5,
                                steps_per_epoch = len(train_data_1_percent),
                                validation_data = test_data,
                                validation_steps =int(0.25 * len(test_data)),
                                #Track model training logs
                                callbacks = [create_tensorboard_callback(dir_name= "transfer_learning",
                                                                        experiment_name = "1_percent_data_aug")]